{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:57:46.971460Z",
     "start_time": "2024-06-20T13:57:45.632731Z"
    }
   },
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import tensorflow.compat.v1.keras as keras\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "# session = tf.Session(config=config)\n",
    "# K.set_session(session)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 16:57:45.825153: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-20 16:57:45.825179: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-20 16:57:45.825872: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-20 16:57:45.830535: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-20 16:57:46.491972: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ahmedh/.local/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T13:57:46.975380Z",
     "start_time": "2024-06-20T13:57:46.972460Z"
    }
   },
   "source": [
    "ddi_model = './trained_model/ddi_model_threshold.h5'\n",
    "feature_model = './trained_model/feature_model_weights.h5'\n",
    "feature_model_weights = './trained_model/feature_model_weights.h5'\n",
    "\n",
    "\n",
    "print(\"Model loaded ===\", str(ddi_model))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded === ./trained_model/ddi_model_threshold.h5\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 1. latent features - significant genes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:57:47.165256Z",
     "start_time": "2024-06-20T13:57:46.977042Z"
    }
   },
   "source": [
    "# LINCS gene info\n",
    "gene_annotation = pd.read_csv('./data/lincs_gene_list.csv', index_col=0)\n",
    "# TWOSIDES drug info\n",
    "ts_drug_annot = pd.read_csv('./data/twosides_drug_info.csv', index_col=0)\n",
    "# TWOSIDES predicted expression\n",
    "twosides_exp = pd.read_csv('./data/twosides_predicted_expression_scaled.csv')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:57:47.176110Z",
     "start_time": "2024-06-20T13:57:47.166152Z"
    }
   },
   "source": [
    "data_path = './data/'\n",
    "train_x = pd.read_csv(data_path+'ddi_example_x.csv')\n",
    "train_y = pd.read_csv(data_path+'ddi_example_y.csv')\n",
    "print('Data loaded === ', train_x.shape, train_y.shape)\n",
    "\n",
    "train_data = pd.concat([train_x, train_y], axis=1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded ===  (19260, 3) (19260, 1)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T14:07:11.895411Z",
     "start_time": "2024-06-20T14:07:11.888037Z"
    }
   },
   "source": [
    "def find_exp(drug_df, ts_exp, column_name):\n",
    "    return pd.merge(drug_df, ts_exp, left_on=column_name, right_on='pubchem', how='left').iloc[:,2:]\n",
    "\n",
    "def extract_expression(classification_model, train_data, drug_id, twosides_exp):\n",
    "\n",
    "    att_a = train_data[(train_data.drug1 == drug_id)&(train_data.label == 1)].drop_duplicates(subset=['drug1','drug2'])\n",
    "    att_b = train_data[(train_data.drug2 == drug_id)&(train_data.label == 1)].drop_duplicates(subset=['drug1','drug2'])\n",
    "    \n",
    "    # drug pair(a,b) & drug pair(b,a)\n",
    "    att_b2 = att_b[['drug2','drug1','SE','label']]\n",
    "    att_b2.columns = ['drug1','drug2','SE','label']\n",
    "    \n",
    "    att_drug_pair = pd.concat([att_a, att_b2], axis=0, ignore_index=True)\n",
    "    \n",
    "    # input\n",
    "    drug1 = find_exp(att_drug_pair[['drug1']], twosides_exp, 'drug1')\n",
    "    drug2 = find_exp(att_drug_pair[['drug2']], twosides_exp, 'drug2')\n",
    "    drug_se = att_drug_pair['SE']\n",
    "    print('Data shape: ', drug1.shape, drug2.shape, drug_se.shape)\n",
    "\n",
    "    attention_layer = K.function([classification_model.layers[0].input, classification_model.layers[1].input, classification_model.layers[6].input],[classification_model.layers[7].output])\n",
    "    attention_d1 = K.function([classification_model.layers[0].input, classification_model.layers[1].input, classification_model.layers[6].input],[classification_model.layers[4].output])\n",
    "    attention_layer2 = K.function([classification_model.layers[0].input, classification_model.layers[1].input, classification_model.layers[6].input],[classification_model.layers[8].output])\n",
    "    attention_d2 = K.function([classification_model.layers[0].input, classification_model.layers[1].input, classification_model.layers[6].input],[classification_model.layers[5].output])\n",
    "\n",
    "    attention_vector = attention_layer([drug1, drug2, drug_se])[0]\n",
    "    attention_vector2 = attention_layer2([drug1, drug2, drug_se])[0]\n",
    "    d1_vector = attention_d1([drug1, drug2, drug_se])[0]\n",
    "    d2_vector = attention_d2([drug1, drug2, drug_se])[0]\n",
    "\n",
    "    se_list_gb_a = pd.DataFrame(pd.merge(att_a[['drug1','drug2']], train_data, on=['drug1','drug2'], how='left').groupby(['drug1','drug2'])['SE'].apply(list))\n",
    "    se_list_gb_b = pd.DataFrame(pd.merge(att_b[['drug1','drug2']], train_data, on=['drug1','drug2'], how='left').groupby(['drug1','drug2'])['SE'].apply(list))\n",
    "    \n",
    "    se_list_gb = pd.concat([se_list_gb_a, se_list_gb_b], axis=0)\n",
    "    \n",
    "    print(se_list_gb.shape)\n",
    "    se_binary = pd.DataFrame(np.zeros((se_list_gb.shape[0], 963)), columns=[x for x in range(0,963)], index=se_list_gb.index)\n",
    "    for index, row in se_list_gb.iterrows():\n",
    "        se_binary.loc[index,row.SE] = 1\n",
    "    print('Corresponding side effects : ', se_binary.shape)    \n",
    "    \n",
    "    return att_drug_pair, attention_vector, attention_vector2, drug1, d1_vector, se_binary"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T14:07:12.798643Z",
     "start_time": "2024-06-20T14:07:12.795419Z"
    }
   },
   "source": [
    "###################################\n",
    "#    Extract weighted genes (Top 100)\n",
    "#    convert index to corresponding gene IDs\n",
    "###################################\n",
    "\n",
    "def extract_top100genes(ddi_pair, gene_header):\n",
    "    index_to_geneID = {k:v[0] for k,v in zip(gene_header.index, gene_header.values)}\n",
    "\n",
    "    temp = pd.DataFrame(ddi_pair, columns=gene_header.values.flatten().tolist())\n",
    "    top_100_gene = pd.DataFrame({col: temp.abs().T[col].nlargest(100).index.tolist() for n, col in enumerate(temp.T)}).T\n",
    "\n",
    "    return top_100_gene"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T14:07:13.794738Z",
     "start_time": "2024-06-20T14:07:13.345737Z"
    }
   },
   "source": [
    "from feature_model.feature_model import Feature_model\n",
    "\n",
    "classification_model = Feature_model()\n",
    "classification_model.load_model(\"./trained_model/\", \"feature_model_weights.h5\")\n",
    "\n",
    "drug_pair_subset, att_mat1, att_mat2, input_d1_mat, d1_att_mat, se_binary = extract_expression(classification_model.model, train_data, 3310, twosides_exp)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 17:07:13.585058: W tensorflow/c/c_api.cc:305] Operation '{name:'dense_11/kernel/Assign' id:1304 op device:{requested: '', assigned: ''} def:{{{node dense_11/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_11/kernel, dense_11/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2024-06-20 17:07:13.645931: W tensorflow/c/c_api.cc:305] Operation '{name:'dense_10/Relu' id:1206 op device:{requested: '', assigned: ''} def:{{{node dense_10/Relu}} = Relu[T=DT_FLOAT, _has_manual_control_dependencies=true](dense_10/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (26, 978) (26, 978) (26,)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Endpoint \"input_5:0\" fed more than once.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m classification_model \u001B[38;5;241m=\u001B[39m Feature_model()\n\u001B[1;32m      4\u001B[0m classification_model\u001B[38;5;241m.\u001B[39mload_model(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./trained_model/\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfeature_model_weights.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m drug_pair_subset, att_mat1, att_mat2, input_d1_mat, d1_att_mat, se_binary \u001B[38;5;241m=\u001B[39m \u001B[43mextract_expression\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclassification_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3310\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtwosides_exp\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[11], line 26\u001B[0m, in \u001B[0;36mextract_expression\u001B[0;34m(classification_model, train_data, drug_id, twosides_exp)\u001B[0m\n\u001B[1;32m     23\u001B[0m attention_layer2 \u001B[38;5;241m=\u001B[39m K\u001B[38;5;241m.\u001B[39mfunction([classification_model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39minput, classification_model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39minput, classification_model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m6\u001B[39m]\u001B[38;5;241m.\u001B[39minput],[classification_model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m8\u001B[39m]\u001B[38;5;241m.\u001B[39moutput])\n\u001B[1;32m     24\u001B[0m attention_d2 \u001B[38;5;241m=\u001B[39m K\u001B[38;5;241m.\u001B[39mfunction([classification_model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39minput, classification_model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39minput, classification_model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m6\u001B[39m]\u001B[38;5;241m.\u001B[39minput],[classification_model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m5\u001B[39m]\u001B[38;5;241m.\u001B[39moutput])\n\u001B[0;32m---> 26\u001B[0m attention_vector \u001B[38;5;241m=\u001B[39m \u001B[43mattention_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdrug1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdrug2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdrug_se\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     27\u001B[0m attention_vector2 \u001B[38;5;241m=\u001B[39m attention_layer2([drug1, drug2, drug_se])[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     28\u001B[0m d1_vector \u001B[38;5;241m=\u001B[39m attention_d1([drug1, drug2, drug_se])[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend.py:4605\u001B[0m, in \u001B[0;36mGraphExecutionFunction.__call__\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m   4596\u001B[0m \u001B[38;5;66;03m# Refresh callable if anything has changed.\u001B[39;00m\n\u001B[1;32m   4597\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   4598\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callable_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   4599\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m feed_arrays \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_feed_arrays\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4603\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m session \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_session\n\u001B[1;32m   4604\u001B[0m ):\n\u001B[0;32m-> 4605\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_callable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeed_arrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeed_symbols\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msymbol_vals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msession\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4607\u001B[0m fetched \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callable_fn(\u001B[38;5;241m*\u001B[39marray_vals, run_metadata\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_metadata)\n\u001B[1;32m   4608\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_fetch_callbacks(fetched[\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fetches) :])\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend.py:4530\u001B[0m, in \u001B[0;36mGraphExecutionFunction._make_callable\u001B[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001B[0m\n\u001B[1;32m   4528\u001B[0m     callable_opts\u001B[38;5;241m.\u001B[39mrun_options\u001B[38;5;241m.\u001B[39mCopyFrom(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_options)\n\u001B[1;32m   4529\u001B[0m \u001B[38;5;66;03m# Create callable.\u001B[39;00m\n\u001B[0;32m-> 4530\u001B[0m callable_fn \u001B[38;5;241m=\u001B[39m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_callable_from_options\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcallable_opts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4531\u001B[0m \u001B[38;5;66;03m# Cache parameters corresponding to the generated callable, so that\u001B[39;00m\n\u001B[1;32m   4532\u001B[0m \u001B[38;5;66;03m# we can detect future mismatches and refresh the callable.\u001B[39;00m\n\u001B[1;32m   4533\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callable_fn \u001B[38;5;241m=\u001B[39m callable_fn\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/client/session.py:1538\u001B[0m, in \u001B[0;36mBaseSession._make_callable_from_options\u001B[0;34m(self, callable_options)\u001B[0m\n\u001B[1;32m   1528\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Returns a handle to a \"callable\" with the given options.\u001B[39;00m\n\u001B[1;32m   1529\u001B[0m \n\u001B[1;32m   1530\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1535\u001B[0m \u001B[38;5;124;03m  A handle to the new callable.\u001B[39;00m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_extend_graph()\n\u001B[0;32m-> 1538\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mBaseSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Callable\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallable_options\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/client/session.py:1496\u001B[0m, in \u001B[0;36mBaseSession._Callable.__init__\u001B[0;34m(self, session, callable_options)\u001B[0m\n\u001B[1;32m   1493\u001B[0m options_ptr \u001B[38;5;241m=\u001B[39m tf_session\u001B[38;5;241m.\u001B[39mTF_NewBufferFromString(\n\u001B[1;32m   1494\u001B[0m     compat\u001B[38;5;241m.\u001B[39mas_bytes(callable_options\u001B[38;5;241m.\u001B[39mSerializeToString()))\n\u001B[1;32m   1495\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1496\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle \u001B[38;5;241m=\u001B[39m \u001B[43mtf_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTF_SessionMakeCallable\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1497\u001B[0m \u001B[43m      \u001B[49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_session\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions_ptr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1499\u001B[0m   tf_session\u001B[38;5;241m.\u001B[39mTF_DeleteBuffer(options_ptr)\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Endpoint \"input_5:0\" fed more than once."
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-20T13:57:50.635641Z",
     "start_time": "2024-06-20T13:57:50.635533Z"
    }
   },
   "source": [
    "drug1_sig_genes = extract_top100genes(att_mat1, gene_header)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "###################################\n",
    "#    Heatmap of changed features\n",
    "###################################\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "temp = pd.DataFrame(d1_att_mat)\n",
    "temp = temp.fillna(0)\n",
    "\n",
    "# Clustermap\n",
    "cg = sns.clustermap(temp, metric='correlation', figsize=(18,10), row_cluster=True, col_cluster=True, \\\n",
    "               cmap='seismic', vmin=-2, vmax=2, center=0, xticklabels=False, yticklabels=False)\n",
    "\n",
    "\n",
    "hm_ax = cg.ax_heatmap\n",
    "hm_ax.add_patch(Rectangle((0,0), 978,temp.shape[0], fill=False, edgecolor='grey', lw=3))\n",
    "cg.ax_col_dendrogram.set_visible(False)\n",
    "\n",
    "ax = cg.fig.add_axes([hm.x0 + hm.width+0.01, hm.y0, 0.01, hm.height])\n",
    "den_row = cg.ax_row_dendrogram.get_position()\n",
    "cg.ax_row_dendrogram.set_position([den_row.x0, den_row.y0, den_row.width*0.5, den_row.height])\n",
    "cg.ax_heatmap.set_position([hm.x0 - den_row.width*0.5, hm.y0, hm.width+den_row.width*0.5, hm.height])\n",
    "\n",
    "# Clustering\n",
    "cluster_number = fcluster(cg.dendrogram_row.linkage, t=5, criterion='maxclust')[cg.dendrogram_row.reordered_ind]\n",
    "cluster_number = cluster_number.reshape(cluster_number.shape[0], 1)\n",
    "\n",
    "sns.heatmap(cluster_number,cmap=sns.color_palette('Accent_r', 10), cbar=False, xticklabels=False, yticklabels=False, ax=ax)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 2. side effects of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# The number of occurrence (drug pairs) of each side effect\n",
    "se_occur = pd.read_csv('./data/twosides_side_effects_occurrence.csv')\n",
    "\n",
    "# TWOSIDES side effect info\n",
    "se_info = pd.read_csv('./data/twosides_side_effect_info.csv', index_col=0)\n",
    "se_name_dict = dict(zip(se_info.SE_map, se_info['Side Effect Name']))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# convert order based on clustering results from the heatmap\n",
    "order = drug_pair_subset.reset_index(drop=True).loc[cg.dendrogram_row.reordered_ind][['drug1','drug2']]\n",
    "se_ordered = pd.merge(order, se_binary.reset_index(), on=['drug1','drug2'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def nCk(n, k):\n",
    "    \"\"\"\n",
    "    A fast way to calculate binomial coefficients by Andrew Dalke (contrib).\n",
    "    \"\"\"\n",
    "    if 0 <= k <= n:\n",
    "        ntok = 1\n",
    "        ktok = 1\n",
    "        for t in range(1, min(k, n - k) + 1):\n",
    "            ntok *= n\n",
    "            ktok *= t\n",
    "            n -= 1\n",
    "        return ntok // ktok\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def hypergeometricTest(N, n, K, k):\n",
    "    odds_ratio = (k/K) / (n/N)\n",
    "    p_value = (nCk(K,k)*nCk(N-K, n-k)) / nCk(N,n)\n",
    "    \n",
    "    return p_value, odds_ratio"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Count #side effects, #drugs for each cluster\n",
    "num_pairs_per_cluster = pd.concat([se_ordered.iloc[:,2:], pd.DataFrame(cluster_number, columns=['ClusterNum'])], axis=1).groupby(['ClusterNum']).count()\n",
    "num_se_per_cluster = pd.concat([se_ordered.iloc[:,2:], pd.DataFrame(cluster_number, columns=['ClusterNum'])], axis=1).groupby(['ClusterNum']).sum()\n",
    "\n",
    "\n",
    "#############################################\n",
    "#    Frequent side effects of each cluster\n",
    "#############################################\n",
    "se_freq_63460 = se_occur['num_occur'].to_dict()\n",
    "\n",
    "se_freq_rank = pd.DataFrame(columns=[x for x in range(0,963)])\n",
    "se_freq_rank_pvalue = pd.DataFrame(columns=[x for x in range(0,963)])\n",
    "\n",
    "for index, row in num_pairs_per_cluster.iterrows():\n",
    "    se_odds = dict()\n",
    "    se_pvalue = dict()\n",
    "    for key,value in dict(row).items():\n",
    "        N = 63460\n",
    "        n = int(se_freq_63460[key])\n",
    "        K = value\n",
    "        k = int(num_se_per_cluster.loc[index,key])\n",
    "\n",
    "        p_value, odds_ratio = hypergeometricTest(N,n,K,k)\n",
    "        \n",
    "        se_odds[key] = odds_ratio\n",
    "        se_pvalue[key] = p_value\n",
    "        \n",
    "    \n",
    "    odds_df = pd.DataFrame(se_odds, index=[index])\n",
    "    se_freq_rank = pd.concat([se_freq_rank, odds_df], axis=0)\n",
    "    \n",
    "    pvalue_df = pd.DataFrame(se_pvalue, index=[index])\n",
    "    se_freq_rank_pvalue = pd.concat([se_freq_rank_pvalue, pvalue_df], axis=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#######################################################################\n",
    "#    TOP frequent side effects of each cluster (side effect names)\n",
    "#######################################################################\n",
    "topSE_cluster = pd.DataFrame({col: se_freq_rank.T[col].nlargest(5).index.tolist() for n, col in enumerate(se_freq_rank.T)}).T\n",
    "topSE_cluster.replace(se_name_dict)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
